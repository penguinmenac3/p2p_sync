{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# App\n",
    "\n",
    "> Watches the filesystem for file changes and creates transactions based on changes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General definitions\n",
    "\n",
    "All imports are done at the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import base64\n",
    "from typing import Dict, Any, List\n",
    "from functools import partial\n",
    "from entangle.entanglement import Entanglement\n",
    "from entangle.client import Client\n",
    "from entangle.server import listen\n",
    "\n",
    "from watchdog.observers import Observer  \n",
    "from watchdog.events import FileSystemEventHandler, DirCreatedEvent, DirDeletedEvent, FileCreatedEvent, FileDeletedEvent, DirModifiedEvent, FileModifiedEvent, DirMovedEvent, FileMovedEvent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_EXCLUDE_PATTERNS = [\".ipynb_checkpoints/\", \".~\", \"__pycache__/\"]\n",
    "_HANDLER = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import hashlib\n",
    "def compute_md5(fname):\n",
    "    hash_md5 = hashlib.md5()\n",
    "    with open(fname, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            hash_md5.update(chunk)\n",
    "    return hash_md5.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# Save the transaction database\n",
    "def save_transactions(database_file: str, database: Dict):\n",
    "    data = json.dumps(database)\n",
    "    with open(database_file, \"w\") as f:\n",
    "        f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# Load the transaction database\n",
    "def load_transactions(database_file) -> Dict:\n",
    "    if not os.path.exists(database_file):\n",
    "        print(\"No database found, creating a new one.\")\n",
    "        database = {}\n",
    "        save_transactions(database_file, database)\n",
    "\n",
    "    with open(database_file, \"r\") as f:\n",
    "        database = json.loads(f.read())\n",
    "    return database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FileChangeHandler(FileSystemEventHandler):\n",
    "    exclude_patterns = []\n",
    "    mappings = {}\n",
    "    database_path = \"database.json\"\n",
    "    \n",
    "    def get_sync_name(self, fname):\n",
    "        for namespace, path in self.mappings.items():\n",
    "            if not path.endswith(\"/\"):\n",
    "                path += \"/\"\n",
    "            if fname.startswith(path):\n",
    "                return fname.replace(path, namespace + \":\")\n",
    "\n",
    "    def on_moved(self, event):\n",
    "        \"\"\"\n",
    "        event.is_directory\n",
    "            True | False\n",
    "        event.src_path\n",
    "            path/to/observed/file\n",
    "        \"\"\"\n",
    "        raw_name = event.src_path.replace(\"\\\\\", \"/\")\n",
    "        if event.src_path.endswith(\"Neues Textdokument.txt\"):\n",
    "            self.on_created(FileCreatedEvent(event.dest_path))\n",
    "        else:\n",
    "            if not isinstance(event, DirMovedEvent):\n",
    "                self.on_deleted(FileDeletedEvent(raw_name))\n",
    "                self.on_created(FileCreatedEvent(event.dest_path))\n",
    "        \n",
    "        #if self.is_excluded(event):\n",
    "        #    return\n",
    "        #\n",
    "        #fname = self.get_sync_name(raw_name)\n",
    "        #fname_moved = self.get_sync_name(event.dest_path)\n",
    "        #\n",
    "        #transactions = load_transactions(self.database_path)\n",
    "        #transaction = {\"timestamp\": time.time(), \"type\": \"moved\", \"new_location\": fname_moved}\n",
    "        #transactions[fname] = transaction\n",
    "        #transaction = {\"timestamp\": time.time(), \"type\": \"moved\", \"old_location\": fname, \"md5\": compute_md5(event.dest_path)}\n",
    "        #transactions[fname] = transaction\n",
    "        #save_transactions(self.database_path, transactions)\n",
    "        \n",
    "        #if len(fname) > 128:\n",
    "        #    fname = fname[:63] + \"...\" + fname[-62:]            \n",
    "        #print(\"\\rMoved: {:<128} (len watches: {})\".format(fname, len(transactions)), end=\"\")\n",
    "\n",
    "\n",
    "    def on_created(self, event):\n",
    "        if event.is_directory:\n",
    "            return\n",
    "        if self.is_excluded(event):\n",
    "            return\n",
    "        \n",
    "        raw_name = event.src_path.replace(\"\\\\\", \"/\")\n",
    "        fname = self.get_sync_name(raw_name)\n",
    "        print(raw_name)\n",
    "        print(fname)\n",
    "        \n",
    "        transactions = load_transactions(self.database_path)\n",
    "        transaction = {\"timestamp\": time.time(), \"type\": \"created\", \"md5\": compute_md5(raw_name)}\n",
    "        transactions[fname] = transaction\n",
    "        save_transactions(self.database_path, transactions)\n",
    "        \n",
    "        if len(fname) > 128:\n",
    "            fname = fname[:63] + \"...\" + fname[-62:]            \n",
    "        print(\"\\rCreated: {:<128} (len watches: {})\".format(fname, len(transactions)), end=\"\")\n",
    "\n",
    "    def on_deleted(self, event):\n",
    "        if self.is_excluded(event):\n",
    "            return\n",
    "        \n",
    "        raw_name = event.src_path.replace(\"\\\\\", \"/\")\n",
    "        fname = self.get_sync_name(raw_name)\n",
    "        \n",
    "        transactions = load_transactions(self.database_path)\n",
    "        transaction = {\"timestamp\": time.time(), \"type\": \"deleted\"}\n",
    "        transactions[fname] = transaction\n",
    "        save_transactions(self.database_path, transactions)\n",
    "        \n",
    "        if len(fname) > 128:\n",
    "            fname = fname[:63] + \"...\" + fname[-62:]\n",
    "        print(\"\\rDeleted: {:<128} (len watches: {})\".format(fname, len(transactions)), end=\"\")\n",
    "\n",
    "    def on_modified(self, event):\n",
    "        if event.is_directory:\n",
    "            return\n",
    "        if self.is_excluded(event):\n",
    "            return\n",
    "        \n",
    "        raw_name = event.src_path.replace(\"\\\\\", \"/\")\n",
    "        fname = self.get_sync_name(raw_name)\n",
    "        \n",
    "        transactions = load_transactions(self.database_path)\n",
    "        transaction = {\"timestamp\": time.time(), \"type\": \"modified\", \"md5\": compute_md5(raw_name)}\n",
    "        transactions[fname] = transaction\n",
    "        save_transactions(self.database_path, transactions)\n",
    "        \n",
    "        if len(fname) > 128:\n",
    "            fname = fname[:63] + \"...\" + fname[-62:]\n",
    "        print(\"\\rModified: {:<128} (len watches: {})\".format(fname, len(transactions)), end=\"\")\n",
    "\n",
    "    def is_excluded(self, event):\n",
    "        raw_name = event.src_path.replace(\"\\\\\", \"/\")\n",
    "        if raw_name.endswith(\"Neues Textdokument.txt\"):\n",
    "            return True\n",
    "\n",
    "        # Filter by exclude pattern.\n",
    "        for pattern in self.exclude_patterns:\n",
    "            pattern = pattern.replace(\"\\\\\", \"/\")\n",
    "            if pattern.endswith(os.sep):\n",
    "                if pattern in raw_name:\n",
    "                    return True\n",
    "                if event.is_directory and raw_name.endswith(pattern[:-1]):\n",
    "                    return True\n",
    "            else:\n",
    "                if raw_name.split(os.sep)[-1].startswith(pattern):\n",
    "                    return True\n",
    "                if raw_name.endswith(pattern):\n",
    "                    return True\n",
    "\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def initial_scan(handler):\n",
    "    tracked_files = []\n",
    "    paths = list(handler.mappings.values())\n",
    "    \n",
    "    # check filelist for deletions or modifications\n",
    "    print(\"\\n\\rScanning Tracked Files\")\n",
    "    transactions = load_transactions(handler.database_path)\n",
    "    for fname, v in transactions.items():\n",
    "        namespace, name = fname.split(\":\")\n",
    "        disk_name = os.path.join(handler.mappings[namespace], name)\n",
    "        if len(fname) > 128:\n",
    "            fname = fname[:63] + \"...\" + fname[-62:]\n",
    "        print(\"\\rScanning: {:<128} (len queue: {})\".format(fname, len(transactions)), end=\"\")\n",
    "        \n",
    "        if os.path.exists(disk_name):\n",
    "            tracked_files.append(disk_name)\n",
    "            if compute_md5(disk_name) != v[\"md5\"]:\n",
    "                handler.on_modified(FileModifiedEvent(disk_name))\n",
    "        elif not v[\"type\"] == \"deleted\":\n",
    "            handler.on_deleted(FileDeletedEvent(disk_name))\n",
    "    print(\"\\n\\rScanning Completed\")\n",
    "\n",
    "    for path in paths:\n",
    "        print(\"n\\rScanning: {}\".format(path))\n",
    "        print(\"(no changes)\", end=\"\")\n",
    "        # check if a file was created that is not yet in filelist\n",
    "        for f in [os.path.join(root, name) for root, dirs, files in os.walk(path) for name in files]:\n",
    "            f = f.replace(\"/\", os.sep)\n",
    "            if f not in tracked_files:\n",
    "                handler.on_created(FileCreatedEvent(f))\n",
    "        print(\"\\n\\rScanning Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def on_retrieve_file(state, entanglement, data: Dict):\n",
    "    print(\"on_retrieve_file: {}\".format(data))\n",
    "    namespace, name = data[\"fname\"].split(\":\")\n",
    "    disk_name = os.path.join(state[\"handler\"].mappings[namespace], name)\n",
    "    transactions = load_transactions(state[\"handler\"].database_path)\n",
    "    transactions[data[\"fname\"]] = data[\"transaction\"]\n",
    "    save_transactions(state[\"handler\"].database_path, transactions)\n",
    "    \n",
    "    if not data[\"transaction\"][\"type\"] == \"deleted\":\n",
    "        with open(disk_name, \"wb\") as f:\n",
    "            f.write(base64.decodestring(data[\"data\"].encode(\"ascii\")))\n",
    "    else:\n",
    "        os.remove(disk_name)\n",
    "\n",
    "    state[\"open_tasks\"] -= 1\n",
    "\n",
    "def retrieve_file(state, entanglement, fname):\n",
    "    print(\"retrieve_file: {}\".format(fname))\n",
    "    data = {}\n",
    "    \n",
    "    namespace, name = fname.split(\":\")\n",
    "    disk_name = os.path.join(state[\"handler\"].mappings[namespace], name)\n",
    "    \n",
    "    transactions = load_transactions(state[\"handler\"].database_path)\n",
    "    data[\"transaction\"] = transactions[fname]\n",
    "    data[\"fname\"] = fname\n",
    "    \n",
    "    if not data[\"transaction\"][\"type\"] == \"deleted\":\n",
    "        with open(disk_name, \"rb\") as f:\n",
    "            data[\"data\"] = base64.encodestring(f.read()).decode(\"ascii\")\n",
    "    entanglement.remote_fun(\"on_retrieve_file\")(data)\n",
    "\n",
    "def on_get_database(state, entanglement, transactions: Dict):\n",
    "    print(\"on_get_database: {}\".format(transactions))\n",
    "    transactions_local = load_transactions(state[\"handler\"].database_path)\n",
    "    \n",
    "    for key in transactions:\n",
    "        namespace, name = key.split(\":\")\n",
    "        if namespace not in state[\"handler\"].mappings:\n",
    "            continue\n",
    "        if key not in transactions_local:\n",
    "            state[\"open_tasks\"] += 1\n",
    "            entanglement.remote_fun(\"sync_retrieve_file\")(key)\n",
    "        elif key in transactions:\n",
    "            local_time = transactions_local[key][\"timestamp\"]\n",
    "            remote_time = transactions[key][\"timestamp\"]\n",
    "            if remote_time > local_time:\n",
    "                state[\"open_tasks\"] += 1\n",
    "                entanglement.remote_fun(\"sync_retrieve_file\")(key)\n",
    "    # TODO compare database against local one\n",
    "    # And request files that are more up to date by others\n",
    "    # delete files that were deleted on remote.\n",
    "    \n",
    "    state[\"open_tasks\"] -= 1\n",
    "\n",
    "def get_database(state, entanglement):\n",
    "    #print(\"get_database\")\n",
    "    transactions = load_transactions(state[\"handler\"].database_path)\n",
    "    entanglement.remote_fun(\"on_sync_get_database\")(transactions)\n",
    "    \n",
    "    \n",
    "def format_len(size):\n",
    "    if size > 1e12:\n",
    "        return \"{:.1f} TB\".format(size/1e12)\n",
    "    elif size > 1e9:\n",
    "        return \"{:.1f} GB\".format(size/1e9)\n",
    "    elif size > 1e6:\n",
    "        return \"{:.1f} MB\".format(size/1e6)\n",
    "    elif size > 1e3:\n",
    "        return \"{:.1f} KB\".format(size/1e3)\n",
    "    else:\n",
    "        return \"{:.1f} B\".format(size)\n",
    "\n",
    "def on_entangle(entanglement):\n",
    "    state = {}\n",
    "    state[\"handler\"] = _HANDLER\n",
    "    entanglement.on_sync_retrieve_file = partial(on_retrieve_file, state, entanglement)\n",
    "    entanglement.on_sync_get_database = partial(on_get_database, state, entanglement)\n",
    "    entanglement.sync_get_database = partial(get_database, state, entanglement)\n",
    "    entanglement.sync_retrieve_file = partial(retrieve_file, state, entanglement)\n",
    "    print(\"Waiting 5 seconds for readiness.\")\n",
    "    time.sleep(5)\n",
    "    print(\"Connected. Syncing...\")\n",
    "    while True:\n",
    "        #print(\"Issuing update of local database...\")\n",
    "        state[\"open_tasks\"] = 1\n",
    "        entanglement.remote_fun(\"sync_get_database\")()\n",
    "        while state[\"open_tasks\"] > 0:\n",
    "            time.sleep(1)\n",
    "\n",
    "        #print(\"Waiting 5 seconds before next sync round.\")\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def run_sync():\n",
    "    global _HANDLER\n",
    "    # Load user_data\n",
    "    if \"AppData\" in os.environ: # Windows\n",
    "        config_file = os.path.join(os.environ[\"AppData\"], \"p2p_sync\", \"config.json\")\n",
    "        syncignore_path = os.path.join(os.environ[\"AppData\"], \"p2p_sync\", \".syncignore\")\n",
    "        database_path = os.path.join(os.environ[\"AppData\"], \"p2p_sync\", \"database.json\")\n",
    "    else: # Linux\n",
    "        config_file = os.path.join(\"/home\", os.environ[\"USER\"], \".p2p_sync\", \"config.json\")\n",
    "        syncignore_path = os.path.join(\"/home\", os.environ[\"USER\"], \".p2p_sync\", \".syncignore\")\n",
    "        database_path = os.path.join(\"/home\", os.environ[\"USER\"], \".p2p_sync\", \"database.json\")\n",
    "    if not os.path.exists(config_file):\n",
    "        raise RuntimeError(\"Config does not exist: {}\".format(config_file))\n",
    "    with open(config_file, \"r\") as f:\n",
    "        config = json.loads(f.read())\n",
    "\n",
    "    # Load exclude patterns\n",
    "    exclude_patterns=_EXCLUDE_PATTERNS\n",
    "    if os.path.exists(syncignore_path):\n",
    "        with open(syncignore_path, \"r\") as f:\n",
    "            exclude_patterns = f.readlines()\n",
    "        exclude_patterns = [pattern.replace(\"\\n\", \"\") for pattern in exclude_patterns]\n",
    "        exclude_patterns = [pattern for pattern in exclude_patterns if pattern != \"\" and not pattern.startswith(\"#\")]\n",
    "        print(\"Ignore Patterns: {}\".format(exclude_patterns))\n",
    "    observer = Observer()\n",
    "    handler = FileChangeHandler()\n",
    "    handler.exclude_patterns = exclude_patterns\n",
    "    handler.database_path = database_path\n",
    "    handler.mappings = config[\"sync_to_local_folder\"]\n",
    "    initial_scan(handler)\n",
    "    _HANDLER = handler\n",
    "    for path in handler.mappings.values():\n",
    "        observer.schedule(handler, path=path, recursive=True)\n",
    "    observer.start()\n",
    "\n",
    "    print(\"Connecting...\")\n",
    "    # 1. Try connecting to all known hosts\n",
    "    clients = []\n",
    "    for hosts in config[\"known_hosts\"]:\n",
    "        clients.append(Client(host=hosts[\"host\"], port=hosts[\"port\"], password=hosts[\"password\"], user=hosts[\"user\"], callback=on_entangle, blocking=False, run_reactor=False))\n",
    "    # 2. Start own server\n",
    "    listen(host=config[\"host\"], port=config[\"port\"], callback=on_entangle, users=config[\"users\"])\n",
    "    \n",
    "    observer.stop()\n",
    "\n",
    "    observer.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "With all implemented it is time to test the implementations.\n",
    "First check what is in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scanning Tracked Files\n",
      "Scanning: git:jlabdev/jlabdev.egg-info/SOURCES.txt                                                                                         (len queue: 399)\n",
      "Scanning Completed\n",
      "Scanning: /home/fuerst/DFKI-Git\n",
      "(no changes)\n",
      "Scanning Completed\n",
      "Scanning: /home/fuerst/Git\n",
      "(no changes)\n",
      "Scanning Completed\n",
      "Connecting...\n",
      "WARN: NO SSL!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.7/threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/fuerst/.virtualenvs/base/lib/python3.7/site-packages/entangle/client.py\", line 92, in create_client\n",
      "    reactor.run(installSignalHandlers=False)\n",
      "  File \"/home/fuerst/.virtualenvs/base/lib/python3.7/site-packages/twisted/internet/base.py\", line 1282, in run\n",
      "    self.startRunning(installSignalHandlers=installSignalHandlers)\n",
      "  File \"/home/fuerst/.virtualenvs/base/lib/python3.7/site-packages/twisted/internet/base.py\", line 1262, in startRunning\n",
      "    ReactorBase.startRunning(self)\n",
      "  File \"/home/fuerst/.virtualenvs/base/lib/python3.7/site-packages/twisted/internet/base.py\", line 763, in startRunning\n",
      "    raise error.ReactorAlreadyRunning()\n",
      "twisted.internet.error.ReactorAlreadyRunning\n",
      "\n"
     ]
    },
    {
     "ename": "ReactorAlreadyRunning",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mReactorAlreadyRunning\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-bcb03933cf91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mrun_sync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-540ecfdd02e2>\u001b[0m in \u001b[0;36mrun_sync\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mclients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhosts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"host\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhosts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"port\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhosts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"password\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhosts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"user\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_entangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# 2. Start own server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mlisten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"host\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"port\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_entangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"users\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mobserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/base/lib/python3.7/site-packages/entangle/server.py\u001b[0m in \u001b[0;36mlisten\u001b[0;34m(host, port, password, callback, users, ssl_root)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# factory.setProtocolOptions(maxConnections=2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mreactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistenSSL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctxFactory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mreactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/base/lib/python3.7/site-packages/twisted/internet/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, installSignalHandlers)\u001b[0m\n\u001b[1;32m   1280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstallSignalHandlers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1282\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartRunning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstallSignalHandlers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstallSignalHandlers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1283\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainLoop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/base/lib/python3.7/site-packages/twisted/internet/base.py\u001b[0m in \u001b[0;36mstartRunning\u001b[0;34m(self, installSignalHandlers)\u001b[0m\n\u001b[1;32m   1260\u001b[0m         \"\"\"\n\u001b[1;32m   1261\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_installSignalHandlers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstallSignalHandlers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1262\u001b[0;31m         \u001b[0mReactorBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartRunning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/base/lib/python3.7/site-packages/twisted/internet/base.py\u001b[0m in \u001b[0;36mstartRunning\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m         \"\"\"\n\u001b[1;32m    762\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_started\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReactorAlreadyRunning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_startedBefore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReactorNotRestartable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mReactorAlreadyRunning\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#export\n",
    "if __name__ == \"__main__\":\n",
    "    run_sync()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
