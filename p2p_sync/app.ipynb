{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# App\n",
    "\n",
    "> Watches the filesystem for file changes and creates transactions based on changes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General definitions\n",
    "\n",
    "All imports are done at the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'OpenSSL'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6febb80bcf8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfunctools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mentangle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentanglement\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEntanglement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mentangle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mentangle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlisten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/base/lib/python3.7/site-packages/entangle/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mentangle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnect_blocking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mentangle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlisten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/base/lib/python3.7/site-packages/entangle/client.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mautobahn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtwisted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwebsocket\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWebSocketClientProtocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWebSocketClientFactory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtwisted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreactor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtwisted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mssl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClientContextFactory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhashlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/base/lib/python3.7/site-packages/twisted/internet/ssl.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m# System imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mOpenSSL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSSL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0msupported\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'OpenSSL'"
     ]
    }
   ],
   "source": [
    "#export\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from typing import Dict, Any, List\n",
    "from functools import partial\n",
    "from entangle.entanglement import Entanglement\n",
    "from entangle.client import Client\n",
    "from entangle.server import listen\n",
    "\n",
    "from watchdog.observers import Observer  \n",
    "from watchdog.events import FileSystemEventHandler, DirCreatedEvent, DirDeletedEvent, FileCreatedEvent, FileDeletedEvent, DirModifiedEvent, FileModifiedEvent, DirMovedEvent, FileMovedEvent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import hashlib\n",
    "def compute_md5(fname):\n",
    "    hash_md5 = hashlib.md5()\n",
    "    with open(fname, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            hash_md5.update(chunk)\n",
    "    return hash_md5.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# Save the transaction database\n",
    "def save_transactions(database_file: str, database: Dict):\n",
    "    data = json.dumps(database)\n",
    "    with open(database_file, \"w\") as f:\n",
    "        f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# Load the transaction database\n",
    "def load_transactions(database_file) -> Dict:\n",
    "    if not os.path.exists(database_file):\n",
    "        print(\"No database found, creating a new one.\")\n",
    "        database = {}\n",
    "        save_transaction_database(database_file, database)\n",
    "\n",
    "    with open(database_file, \"r\") as f:\n",
    "        database = json.loads(f.read())\n",
    "    print(\"Database successfully loaded. {} transactions, {} lru_filenames\".format(len(database[\"transactions\"]), len(database[\"lru_filenames\"])))\n",
    "    return database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FileChangeHandler(FileSystemEventHandler):\n",
    "    exclude_patterns = []\n",
    "    mappings = {}\n",
    "    database_path = \"database.json\"\n",
    "    \n",
    "    def get_sync_name(self, fname):\n",
    "        for namespace, path in mappings.items():\n",
    "            if not path.endswith(\"/\"):\n",
    "                path += \"/\"\n",
    "            if fname.startswith(path):\n",
    "                return fname.replace(path, namespace + \":\")\n",
    "\n",
    "    def on_moved(self, event):\n",
    "        \"\"\"\n",
    "        event.is_directory\n",
    "            True | False\n",
    "        event.src_path\n",
    "            path/to/observed/file\n",
    "        \"\"\"\n",
    "        if self.is_excluded(event):\n",
    "            return\n",
    "        \n",
    "        fname = self.get_sync_name(event.src_path)\n",
    "        fname_moved = self.get_sync_name(event.dest_path)\n",
    "        \n",
    "        transactions = load_transactions(self.database_path)\n",
    "        transaction = {\"timestamp\": time.time(), \"type\": \"moved\", \"new_location\": fname_moved}\n",
    "        transactions[fname] = transaction\n",
    "        transaction = {\"timestamp\": time.time(), \"type\": \"moved\", \"old_location\": fname, \"md5\": compute_md5(event.dest_path)}\n",
    "        transactions[fname] = transaction\n",
    "        save_transactions(self.database_path, transactions)\n",
    "        \n",
    "        if len(fname) > 128:\n",
    "            fname = fname[:63] + \"...\" + fname[-62:]            \n",
    "        print(\"\\rMoved: {:<128} (len queue: {})\".format(fname, len(transactions)), end=\"\")\n",
    "\n",
    "\n",
    "    def on_created(self, event):\n",
    "        if event.is_directory:\n",
    "            return\n",
    "        if self.is_excluded(event):\n",
    "            return\n",
    "        \n",
    "        fname = self.get_sync_name(event.src_path)\n",
    "        \n",
    "        transactions = load_transactions(self.database_path)\n",
    "        transaction = {\"timestamp\": time.time(), \"type\": \"created\", \"md5\": compute_md5(event.src_path)}\n",
    "        transactions[fname] = transaction\n",
    "        save_transactions(self.database_path, transactions)\n",
    "        \n",
    "        if len(fname) > 128:\n",
    "            fname = fname[:63] + \"...\" + fname[-62:]            \n",
    "        print(\"\\rCreated: {:<128} (len queue: {})\".format(fname, len(transactions)), end=\"\")\n",
    "\n",
    "    def on_deleted(self, event):\n",
    "        if self.is_excluded(event):\n",
    "            return\n",
    "        \n",
    "        fname = self.get_sync_name(event.src_path)\n",
    "        \n",
    "        transactions = load_transactions(self.database_path)\n",
    "        transaction = {\"timestamp\": time.time(), \"type\": \"deleted\"}\n",
    "        transactions[fname] = transaction\n",
    "        save_transactions(self.database_path, transactions)\n",
    "        \n",
    "        if len(fname) > 128:\n",
    "            fname = fname[:63] + \"...\" + fname[-62:]\n",
    "        print(\"\\rDeleted: {:<128} (len queue: {})\".format(fname, len(transactions)), end=\"\")\n",
    "\n",
    "    def on_modified(self, event):\n",
    "        if event.is_directory:\n",
    "            return\n",
    "        if self.is_excluded(event):\n",
    "            return\n",
    "        fname = self.get_sync_name(event.src_path)\n",
    "        \n",
    "        transactions = load_transactions(self.database_path)\n",
    "        transaction = {\"timestamp\": time.time(), \"type\": \"modified\", \"md5\": compute_md5(event.src_path)}\n",
    "        transactions[fname] = transaction\n",
    "        save_transactions(self.database_path, transactions)\n",
    "        \n",
    "        if len(fname) > 128:\n",
    "            fname = fname[:63] + \"...\" + fname[-62:]\n",
    "        print(\"\\rModified: {:<128} (len queue: {})\".format(fname, len(transactions)), end=\"\")\n",
    "\n",
    "    def is_excluded(self, event):\n",
    "        if event.src_path.endswith(\"Neues Textdokument.txt\"):\n",
    "            return True\n",
    "\n",
    "        # Filter by exclude pattern.\n",
    "        for pattern in self.exclude_patterns:\n",
    "            pattern = pattern.replace(\"\\\\\", os.sep)\n",
    "            pattern = pattern.replace(\"/\", os.sep)\n",
    "            if pattern.endswith(os.sep):\n",
    "                if pattern in event.src_path:\n",
    "                    return True\n",
    "                if event.is_directory and event.src_path.endswith(pattern[:-1]):\n",
    "                    return True\n",
    "            else:\n",
    "                if event.src_path.split(os.sep)[-1].startswith(pattern):\n",
    "                    return True\n",
    "                if event.src_path.endswith(pattern):\n",
    "                    return True\n",
    "\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def initial_scan(handler):\n",
    "    tracked_files = []\n",
    "    paths = list(handler.mappings.values())\n",
    "    \n",
    "    # check filelist for deletions or modifications\n",
    "    print(\"\\n\\rScanning Tracked Files\")\n",
    "    transactions = load_transactions(handler.database_path)\n",
    "    for fname, v in transactions:\n",
    "        namespace, name = fname.split(\":\")\n",
    "        disk_name = os.path.join(handler.mappings[namespace], name)\n",
    "        if len(fname) > 128:\n",
    "            fname = fname[:63] + \"...\" + fname[-62:]\n",
    "        print(\"\\rScanning: {:<128} (len queue: {})\".format(fname, len(_transaction_send_queue)), end=\"\")\n",
    "        \n",
    "        if os.path.exists(disk_name):\n",
    "            tracked_files.append(t.local_fname)\n",
    "            if compute_md5(disk_name) != v[\"md5\"]:\n",
    "                handler.on_modified(FileModifiedEvent(t.local_fname))\n",
    "        elif not v[\"type\"] == \"deleted\":\n",
    "            handler.on_deleted(FileDeletedEvent(disk_name))\n",
    "    print(\"\\n\\rScanning Completed\")\n",
    "\n",
    "    for path in paths:\n",
    "        print(\"n\\rScanning: {}\".format(path))\n",
    "        print(\"(no changes)\", end=\"\")\n",
    "        # check if a file was created that is not yet in filelist\n",
    "        for f in [os.path.join(root, name) for root, dirs, files in os.walk(path) for name in files]:\n",
    "            f = f.replace(\"/\", os.sep)\n",
    "            if f not in tracked_files:\n",
    "                handler.on_created(FileCreatedEvent(f))\n",
    "        print(\"\\n\\rScanning Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def on_retrieve_file(state, entanglement, data: Dict):\n",
    "    print(\"on_retrieve_file: {}\".format(data))\n",
    "    namespace, name = data[\"fname\"].split(\":\")\n",
    "    disk_name = os.path.join(state[\"handler\"].mappings[namespace], name)\n",
    "    transactions = load_transactions(state[\"handler\"].database_path)\n",
    "    transactions[data[\"fname\"]] = data[\"transaction\"]\n",
    "    save_transactions(state[\"handler\"].database_path, transactions)\n",
    "    with open(disk_name, \"wb\") as f:\n",
    "        f.write(base64.b64decode(data[\"data\"].encode(\"utf-8\")))\n",
    "\n",
    "    state[\"open_tasks\"] -= 1\n",
    "\n",
    "def retrieve_file(state, entanglement, fname):\n",
    "    print(\"retrieve_file: {}\".format(fname))\n",
    "    data = {}\n",
    "    \n",
    "    namespace, name = data[\"fname\"].split(\":\")\n",
    "    disk_name = os.path.join(state[\"handler\"].mappings[namespace], name)\n",
    "    \n",
    "    transactions = load_transactions(state[\"handler\"].database_path)\n",
    "    data[\"transaction\"] = transactions[fname]\n",
    "    data[\"fname\"] = fname\n",
    "    \n",
    "    with open(disk_name, \"rb\") as f:\n",
    "        data[\"data\"] = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "    entanglement.remote_fun(\"on_retrieve_file\")(transactions)\n",
    "\n",
    "def on_get_database(state, entanglement, transactions: Dict):\n",
    "    print(\"on_get_database: {}\".format(transactions))\n",
    "    transactions_local = load_transactions(state[\"handler\"].database_path)\n",
    "    \n",
    "    # TODO compare database against local one\n",
    "    # And request files that are more up to date by others\n",
    "    # delete files that were deleted on remote.\n",
    "    \n",
    "    state[\"open_tasks\"] -= 1\n",
    "\n",
    "def get_database(state, entanglement):\n",
    "    print(\"get_database\")\n",
    "    transactions = load_transactions(state[\"handler\"].database_path)\n",
    "    entanglement.remote_fun(\"on_sync_get_database\")(transactions)\n",
    "    \n",
    "    \n",
    "def format_len(size):\n",
    "    if size > 1e12:\n",
    "        return \"{:.1f} TB\".format(size/1e12)\n",
    "    elif size > 1e9:\n",
    "        return \"{:.1f} GB\".format(size/1e9)\n",
    "    elif size > 1e6:\n",
    "        return \"{:.1f} MB\".format(size/1e6)\n",
    "    elif size > 1e3:\n",
    "        return \"{:.1f} KB\".format(size/1e3)\n",
    "    else:\n",
    "        return \"{:.1f} B\".format(size)\n",
    "\n",
    "def on_entangle(entanglement):\n",
    "    state = {}\n",
    "    entanglement.on_sync_retrieve_file = partial(on_retrieve_file, state, entanglement)\n",
    "    entanglement.on_sync_get_database = partial(on_get_database, state, entanglement)\n",
    "    entanglement.sync_get_database = partial(get_database, state, entanglement)\n",
    "    print(\"Waiting 5 seconds for server to be ready.\")\n",
    "    time.sleep(5)\n",
    "    print(\"Connected. Syncing...\")\n",
    "    while True:\n",
    "        print(\"Issuing update of local database...\")\n",
    "        state[\"open_tasks\"] = 1\n",
    "        entanglement.remote_fun(\"sync_get_database\")()\n",
    "        while state[\"open_tasks\"] > 0:\n",
    "            time.sleep(1)\n",
    "\n",
    "        print(\"Waiting 5 seconds before next sync round.\")\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def run_sync():\n",
    "    # Load user_data\n",
    "    if \"AppData\" in os.environ: # Windows\n",
    "        config_file = os.path.join(os.environ[\"AppData\"], \"backup_sync\", \"config.json\")\n",
    "        syncignore_path = os.path.join(os.environ[\"AppData\"], \"backup_sync\", \".syncignore\")\n",
    "        database_path = os.path.join(os.environ[\"AppData\"], \"backup_sync\", \"database.json\")\n",
    "    else: # Linux\n",
    "        config_file = os.path.join(\"/home\", os.environ[\"USER\"], \".backup_sync\", \"config.json\")\n",
    "        syncignore_path = os.path.join(\"/home\", os.environ[\"USER\"], \".backup_sync\", \".syncignore\")\n",
    "        database_path = os.path.join(\"/home\", os.environ[\"USER\"], \".backup_sync\", \"database.json\")\n",
    "    if not os.path.exists(config_file):\n",
    "        raise RuntimeError(\"Config does not exist: {}\".format(config_file))\n",
    "    with open(config_file, \"r\") as f:\n",
    "        config = json.loads(f.read())\n",
    "\n",
    "    # Load exclude patterns\n",
    "    exclude_patterns=_EXCLUDE_PATTERNS\n",
    "    if os.path.exists(syncignore_path):\n",
    "        with open(syncignore_path, \"r\") as f:\n",
    "            exclude_patterns = f.readlines()\n",
    "        exclude_patterns = [pattern.replace(\"\\n\", \"\") for pattern in exclude_patterns]\n",
    "        exclude_patterns = [pattern for pattern in exclude_patterns if pattern != \"\" and not pattern.startswith(\"#\")]\n",
    "        print(\"Ignore Patterns: {}\".format(exclude_patterns))\n",
    "    observer = Observer()\n",
    "    handler = FileChangeHandler()\n",
    "    handler.exclude_patterns = exclude_patterns\n",
    "    handler.database_path = database_path\n",
    "    handler.mappings = config[\"sync_to_local_folder\"]\n",
    "    initial_scan(handler)\n",
    "    for path in paths.values():\n",
    "        observer.schedule(handler, path=path, recursive=True)\n",
    "    observer.start()\n",
    "\n",
    "    print(\"Connecting...\")\n",
    "    # 1. Try connecting to all known hosts\n",
    "    clients = []\n",
    "    for hosts in config[\"known_hosts\"]:\n",
    "        clients.append(Client(host=hosts[\"host\"], port=hosts[\"port\"], password=hosts[\"password\"], user=hosts[\"user\"], callback=on_entangle, blocking=False))\n",
    "    # 2. Start own server\n",
    "    listen(host=config[\"host\"], port=config[\"port\"], callback=on_entangle, users=config[\"users\"])\n",
    "    \n",
    "    observer.stop()\n",
    "\n",
    "    observer.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "With all implemented it is time to test the implementations.\n",
    "First check what is in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "if __name__ == \"__main__\":\n",
    "    run_sync()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
